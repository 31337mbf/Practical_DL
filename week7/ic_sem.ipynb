{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "DeepLarning Couse HSE 2016 fall: Arseniy Ashuha, you can text me ```ars.ashuha@gmail.com```, ```https://vk.com/ars.ashuha``` \n",
    "\n",
    "<h1 align=\"center\"> Image Captioning </h1> \n",
    "\n",
    "Тут мы проведем Вас через реализацию аннотирования картинок. Вам нужно помнить про глубокие и рекуррентные сети. \n",
    "\n",
    "Скачайте датасет, в нем уже построены признаки для изображений с помощью GoogleNet.\n",
    "\n",
    "```bash\n",
    "export dataset=https://s3.amazonaws.com/lasagne/recipes/datasets/coco_with_cnn_features.pkl\n",
    "curl -o ./files/coco_with_cnn_features.pkl $dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all staff\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import theano\n",
    "import lasagne\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import * \n",
    "\n",
    "from time import time\n",
    "from utils import googlenet\n",
    "from lasagne import layers as ll\n",
    "from collections import Counter\n",
    "from lasagne.utils import floatX\n",
    "from utils.utils import get_data_batch, prep_batch_for_network\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "dataset = pickle.load(open('files/coco_with_cnn_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[0]['sentences']['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a Vocabulary\n",
    "allwords = <Словарь слово:сколько раз встретилось> \n",
    "\n",
    "vocab  = ['#START#', '#END#']\n",
    "vocab += [k for k, v in allwords.items() if v >= 5]\n",
    "\n",
    "word_to_index = {w: i for i, w in enumerate(vocab)}\n",
    "index_to_word = <Словарик индекс:слово>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define of different constant \n",
    "EMBED = 128\n",
    "BATCH_SIZE = 100\n",
    "SEQUENCE_LENGTH = 10\n",
    "CNN_FEATURE_SIZE = 1000\n",
    "MAX_SENTENCE_LENGTH = SEQUENCE_LENGTH - 3 # 1 for image, 1 for start token, 1 for end token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваша модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Variable\n",
    "x_snt = T.imatrix() # batch_size x words_ids \n",
    "x_img = <что-то с признаками из изображений> \n",
    "y_snt = <правильные слова>\n",
    "mask  = <Маска чтобы предсказывать короткие последовательности>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Layer for words \n",
    "embed_snt = ll.InputLayer((None, SEQUENCE_LENGTH - 1), x_snt)\n",
    "embed_snt = <Слой с кодированием каждого слова вектором> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Layer for image features\n",
    "embed_img = ll.InputLayer((None, CNN_FEATURE_SIZE), x_img)\n",
    "embed_img = <Слой преобразующий признаки картинки к размерности = размерности вектора для каждого слова>\n",
    "embed_img = ll.ReshapeLayer(embed_img, ([0], 1, [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatinate image features and word embedings in one sequence \n",
    "rnn_in = <Соедините embed_img и embed_snt в одну последовательность>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a recurent part \n",
    "rnn_in = <Добавьте немного регуляризации>\n",
    "rnn = <Теперь нужно рекурентную часть сделать>\n",
    "rnn_out = <Добавьте немного регуляризации>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decoding of rnn hiden states\n",
    "rnn_out = <Нужно сделать Reshape чтобы все хорошо можно было декодировать>\n",
    "decoder = <Декодирование через DenseLayer>\n",
    "decoder = <Обратный Reshape> # <--- Тут уже должен быть тензор (батч, длина последовательности, размер словаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_cross_ent(net_output, mask, targets):\n",
    "    preds, targets = T.reshape(net_output, (-1, len(vocab))), T.flatten(targets)\n",
    "    # Сумма только по правильной длине\n",
    "    cost = T.nnet.categorical_crossentropy(preds, targets)[T.flatten(mask).nonzero()]\n",
    "    return cost\n",
    "\n",
    "output = ll.get_output(decoder, deterministic=False)\n",
    "loss = T.mean(calc_cross_ent(output, mask, y_snt))\n",
    "all_params = ll.get_all_params(decoder)\n",
    "updates = <Метод оптимизации>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (x_cnn, x_sentence, mask, y_sentence)\n",
    "f_train = <Скомпилируйте функцию для обучения>\n",
    "f_val   = <Скомпилируйте функцию для обучения>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_train, norm, st = 0, 0, time()\n",
    "for iteration in range(0, 5000):\n",
    "    print '.',\n",
    "    batch = prep_batch_for_network(\n",
    "        get_data_batch(dataset, BATCH_SIZE, MAX_SENTENCE_LENGTH), SEQUENCE_LENGTH, word_to_index)\n",
    "    x_cnn, x_sentence, y_sentence, mask = batch\n",
    "    loss_train += f_train(x_cnn, x_sentence, mask, y_sentence)\n",
    "    if not iteration % 40:\n",
    "        print int(time() - st), 'sec.',\n",
    "        st = time()\n",
    "        \n",
    "        batch = get_data_batch(dataset, BATCH_SIZE, MAX_SENTENCE_LENGTH, split='val')\n",
    "        x_cnn, x_sentence, y_sentence, mask = prep_batch_for_network(batch, SEQUENCE_LENGTH, word_to_index)\n",
    "        loss_val = f_val(x_cnn, x_sentence, mask, y_sentence)\n",
    "        print('\\nIt: {}, loss_train: {}, val loss: {}'.format(iteration, loss_train/40, loss_val))\n",
    "        loss_train, norm = 0, 0\n",
    "        \n",
    "print '\\nFinish =)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Применение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузим сеть GoogLeNet\n",
    "cnn_layers = googlenet.build_model()\n",
    "cnn_input_var = cnn_layers['input'].input_var\n",
    "cnn_feature_layer = cnn_layers['loss3/classifier']\n",
    "cnn_output_layer = cnn_layers['prob']\n",
    "\n",
    "get_cnn_features = theano.function([cnn_input_var], lasagne.layers.get_output(cnn_feature_layer))\n",
    "\n",
    "gnw = pickle.load(open('files/blvc_googlenet.pkl'))\n",
    "CLASSES = np.array(gnw['synset words'])\n",
    "lasagne.layers.set_all_param_values(cnn_output_layer, gnw['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = plt.imread('./files/Dog-and-Cat.jpg')\n",
    "rawim, cnn_im = prep_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(121); plt.imshow(im);\n",
    "plt.subplot(122); plt.imshow(rawim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Выведим самые вероятные классы\n",
    "p = get_cnn_features(cnn_im)\n",
    "max_prob_idx = p.argsort()[0][-5:]\n",
    "\n",
    "for i in reversed(max_prob_idx):\n",
    "    print CLASSES[i], p[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Получим функцию для генепации следующего слова\n",
    "output = ll.get_output(decoder, deterministic=False)\n",
    "f = theano.function([x_img, x_snt], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x_cnn):\n",
    "    x_sentence = np.zeros((1, SEQUENCE_LENGTH - 1), dtype='int32')\n",
    "    words = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        p0 = f(x_cnn, x_sentence)\n",
    "        pa = p0.argmax(-1)\n",
    "        tok = pa[0][i]\n",
    "        word = index_to_word[tok]\n",
    "        if word == '#END#' or i >= SEQUENCE_LENGTH - 1:\n",
    "            return ' '.join(words)\n",
    "        else:\n",
    "            x_sentence[0][i] = tok\n",
    "            if word != '#START#':\n",
    "                words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cnn = get_cnn_features(cnn_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample some predictions\n",
    "for _ in range(10):\n",
    "    print(predict(x_cnn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
