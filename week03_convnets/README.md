Lecture slides - __[click here](https://yadi.sk/i/ibh5co-d3N6EM5)__

__Note__: Seminars assume that you remember batch normalization and dropout from last lecture. If you don't, go recap week2.


## Materials
- [russian] Convolutional networks - [video](https://yadi.sk/i/hDIkaR4H3EtnXM)
- [english] Convolutional networks (karpathy) - [video](https://www.youtube.com/watch?v=AQirPKrAyDg)

- Reading
  - http://cs231n.github.io/convolutional-networks/
  - http://cs231n.github.io/understanding-cnn/
  - [a deep learning neophite cheat sheet](http://www.kdnuggets.com/2016/03/must-know-tips-deep-learning-part-1.html)
  - [more stuff for vision](https://bavm2013.splashthat.com/img/events/46439/assets/34a7.ranzato.pdf)
  - a [CNN trainer in a browser](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html)
  
- Bonus reading:
  - Interpreting neural network predictions: [distill.pub post](https://distill.pub/2018/building-blocks/)


## Practice

As usual, go to seminar_pytorch.ipynb and folow instructons from there.
There's also an alternative version for other frameworks (theano+lasagne, tensorflow+keras) available.
